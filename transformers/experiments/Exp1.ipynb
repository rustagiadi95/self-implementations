{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## why not put attention heads as 3rd dimension? (BATCH_SIZE, ATTENTION_HEADS, SEQ_LEN, D_MODEL)\n",
    "## Apply padding masks to multi head attention\n",
    "## how to stack transformer encoder decoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Blocks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Head_Attention(nn.Module) :\n",
    "\n",
    "    def __init__(self, n_heads, d_model, d_key_query = None, d_value = None, mask = False) :\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.mask = mask\n",
    "\n",
    "        if not d_key_query : d_key_query = d_model//n_heads\n",
    "        if not d_value : d_value = d_model//n_heads\n",
    "\n",
    "        self.key = nn.Linear(d_model, d_key_query)\n",
    "        self.query = nn.Linear(d_model, d_key_query)\n",
    "        self.value = nn.Linear(d_model, d_value)\n",
    "\n",
    "        self.linear  = nn.Linear(d_value * n_heads, d_model)\n",
    "\n",
    "    def forward(self, key, query, value) :\n",
    "        \n",
    "        batch_size = key.size(0)\n",
    "        seq_len = key.size(1)\n",
    "        \n",
    "        key = key.unsqueeze(1).repeat_interleave(self.n_heads, dim = 1)\n",
    "        query = query.unsqueeze(1).repeat_interleave(self.n_heads, dim = 1)\n",
    "        value = value.unsqueeze(1).repeat_interleave(self.n_heads, dim = 1)\n",
    "\n",
    "        ## creating the key, query, value matrices for the input\n",
    "        keys = F.gelu(self.key(key))\n",
    "        queries = F.gelu(self.query(query))\n",
    "        values = F.gelu(self.value(value))\n",
    "\n",
    "        ## scalar dot product attention\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(2, 3))/torch.sqrt(torch.tensor(self.d_model))\n",
    "        attention_scores = torch.softmax(attention_scores, dim = 3)\n",
    "\n",
    "        ## create mask and apply\n",
    "        mask = torch.ones(batch_size, self.n_heads, seq_len, seq_len)\n",
    "        if self.mask :\n",
    "            mask = torch.tril(mask)\n",
    "        attention_scores = torch.matmul(mask, attention_scores)\n",
    "\n",
    "        ## matmul with the values\n",
    "        values_with_attention = torch.matmul(attention_scores, values)\n",
    "        concatenated_vectors = torch.reshape(torch.stack([values_with_attention[:, idx, :, :] for idx in range(self.n_heads)], dim = 2), (batch_size, seq_len, -1))\n",
    "        output = F.gelu(self.linear(concatenated_vectors))\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add and layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayerNormalization(nn.Module) :\n",
    "\n",
    "    def __init__(self, sequence_len, d_model) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm([sequence_len, d_model])\n",
    "\n",
    "    def forward(self, x, mha_output) :\n",
    "\n",
    "        return self.layer_norm(x + mha_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PointWise Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWise_Feedforward(nn.Module) :\n",
    "\n",
    "    def __init__(self, d_ff, d_model) :\n",
    "        super().__init__();\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x) :\n",
    "\n",
    "        linear1_output = self.linear1(x)\n",
    "        linear2_output = self.linear2(F.relu(linear1_output))\n",
    "\n",
    "        return linear2_output\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single transformer layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Layer(nn.Module) :\n",
    "\n",
    "    def __init__(self, n_heads, max_seq_len, d_model, d_ff) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = Multi_Head_Attention(n_heads, d_model)\n",
    "        self.layer_norm = AddLayerNormalization(max_seq_len, d_model)\n",
    "        self.pff = PointWise_Feedforward(d_ff, d_model)\n",
    "        self.layer_norm2 = AddLayerNormalization(max_seq_len, d_model)\n",
    "\n",
    "    def forward(self, x) :\n",
    "\n",
    "        mha_output = self.mha(key = x, query = x, value = x)\n",
    "        norm_output1 = self.layer_norm(x, mha_output)\n",
    "\n",
    "        pff_output = self.pff(norm_output1)\n",
    "        norm_output2 = self.layer_norm2(norm_output1, pff_output)\n",
    "\n",
    "        return norm_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder_Layer(8, 5, 512, 2048)\n",
    "\n",
    "with torch.no_grad() :\n",
    "    t = torch.rand(2, 5, 512)\n",
    "    output = model(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.6915e-01, 2.3101e-01, 1.8677e-01, 3.2823e-01, 3.3690e-01,\n",
       "           8.1443e-01],\n",
       "          [2.2544e-02, 6.1115e-01, 9.3989e-01, 9.0730e-01, 9.9352e-01,\n",
       "           9.9025e-01],\n",
       "          [4.8508e-01, 7.8124e-02, 3.3347e-01, 8.0652e-01, 4.0264e-01,\n",
       "           1.4739e-01],\n",
       "          [3.7981e-02, 6.8632e-01, 5.8275e-01, 7.5194e-01, 6.3034e-01,\n",
       "           6.8327e-01],\n",
       "          [7.0750e-01, 8.4914e-01, 6.0135e-01, 6.9475e-01, 8.7851e-01,\n",
       "           1.9928e-01]],\n",
       "\n",
       "         [[6.3917e-01, 4.5646e-02, 9.1937e-01, 8.9844e-01, 5.1065e-01,\n",
       "           9.8977e-01],\n",
       "          [2.6453e-01, 1.4332e-01, 2.2712e-01, 4.8705e-01, 7.6302e-01,\n",
       "           7.6922e-01],\n",
       "          [6.1331e-02, 1.5677e-01, 8.2732e-01, 9.2498e-01, 5.2458e-01,\n",
       "           7.4341e-02],\n",
       "          [6.1056e-02, 8.2466e-01, 4.1147e-01, 6.4349e-01, 1.5110e-01,\n",
       "           3.1953e-01],\n",
       "          [7.2273e-01, 1.9713e-01, 5.5603e-01, 8.7607e-01, 7.6079e-01,\n",
       "           9.1249e-01]],\n",
       "\n",
       "         [[8.3862e-01, 5.3867e-01, 5.1706e-01, 8.5575e-01, 9.6617e-01,\n",
       "           2.4108e-01],\n",
       "          [7.8270e-01, 5.6985e-01, 1.5982e-01, 3.7485e-01, 3.6404e-01,\n",
       "           2.6004e-01],\n",
       "          [7.2281e-01, 7.5024e-01, 3.4908e-01, 3.4458e-01, 1.4865e-01,\n",
       "           7.5744e-01],\n",
       "          [8.2653e-01, 2.7210e-01, 7.5463e-01, 1.9109e-01, 4.0983e-01,\n",
       "           5.5320e-01],\n",
       "          [8.0141e-01, 6.9035e-01, 3.3284e-01, 9.0685e-01, 5.2012e-01,\n",
       "           4.5754e-01]]],\n",
       "\n",
       "\n",
       "        [[[5.7527e-01, 7.6890e-01, 2.2973e-01, 2.5378e-03, 7.5288e-01,\n",
       "           6.1307e-01],\n",
       "          [9.4741e-01, 3.2619e-01, 1.9329e-01, 2.3312e-01, 9.0410e-01,\n",
       "           1.9239e-02],\n",
       "          [5.2327e-01, 6.4609e-01, 5.4561e-01, 1.8429e-01, 4.0426e-01,\n",
       "           7.9262e-02],\n",
       "          [1.1733e-03, 2.0920e-01, 3.8062e-01, 7.6920e-01, 2.6934e-01,\n",
       "           8.3331e-01],\n",
       "          [1.3987e-01, 1.7269e-01, 5.6507e-01, 3.0897e-01, 7.8534e-01,\n",
       "           3.7702e-01]],\n",
       "\n",
       "         [[1.3034e-01, 9.1983e-01, 3.6165e-01, 3.7894e-01, 7.9992e-01,\n",
       "           8.6322e-01],\n",
       "          [5.9635e-01, 5.0683e-01, 5.2516e-01, 8.2776e-01, 4.8167e-04,\n",
       "           7.9498e-01],\n",
       "          [9.5834e-01, 6.1531e-01, 9.2797e-01, 3.5991e-01, 1.6803e-01,\n",
       "           6.5304e-01],\n",
       "          [1.0479e-01, 1.9877e-01, 9.3850e-02, 5.8323e-01, 9.4285e-01,\n",
       "           6.7505e-01],\n",
       "          [5.5258e-01, 7.5297e-01, 4.8599e-01, 1.7751e-01, 7.1228e-01,\n",
       "           9.8650e-01]],\n",
       "\n",
       "         [[2.9916e-01, 4.5821e-01, 8.4067e-01, 9.3575e-01, 5.1400e-01,\n",
       "           1.0528e-01],\n",
       "          [4.9209e-01, 7.3881e-01, 8.8582e-01, 5.9218e-01, 2.7211e-01,\n",
       "           7.6992e-01],\n",
       "          [2.4870e-01, 3.0117e-01, 5.2956e-01, 1.0406e-01, 7.1789e-02,\n",
       "           7.3685e-01],\n",
       "          [1.9003e-01, 9.5878e-01, 7.7554e-01, 1.9861e-02, 5.0951e-01,\n",
       "           7.8584e-02],\n",
       "          [4.8321e-01, 4.8538e-01, 2.0434e-01, 2.8275e-02, 3.5162e-01,\n",
       "           5.5383e-01]]]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2, 3, 5, 6)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.6915e-01, 2.3101e-01, 1.8677e-01, 3.2823e-01, 3.3690e-01,\n",
       "           8.1443e-01],\n",
       "          [5.9170e-01, 8.4216e-01, 1.1267e+00, 1.2355e+00, 1.3304e+00,\n",
       "           1.8047e+00],\n",
       "          [1.0768e+00, 9.2028e-01, 1.4601e+00, 2.0421e+00, 1.7331e+00,\n",
       "           1.9521e+00],\n",
       "          [1.1148e+00, 1.6066e+00, 2.0429e+00, 2.7940e+00, 2.3634e+00,\n",
       "           2.6353e+00],\n",
       "          [1.8223e+00, 2.4557e+00, 2.6442e+00, 3.4887e+00, 3.2419e+00,\n",
       "           2.8346e+00]],\n",
       "\n",
       "         [[6.3917e-01, 4.5646e-02, 9.1937e-01, 8.9844e-01, 5.1065e-01,\n",
       "           9.8977e-01],\n",
       "          [9.0370e-01, 1.8897e-01, 1.1465e+00, 1.3855e+00, 1.2737e+00,\n",
       "           1.7590e+00],\n",
       "          [9.6503e-01, 3.4574e-01, 1.9738e+00, 2.3105e+00, 1.7982e+00,\n",
       "           1.8333e+00],\n",
       "          [1.0261e+00, 1.1704e+00, 2.3853e+00, 2.9540e+00, 1.9494e+00,\n",
       "           2.1529e+00],\n",
       "          [1.7488e+00, 1.3675e+00, 2.9413e+00, 3.8300e+00, 2.7101e+00,\n",
       "           3.0653e+00]],\n",
       "\n",
       "         [[8.3862e-01, 5.3867e-01, 5.1706e-01, 8.5575e-01, 9.6617e-01,\n",
       "           2.4108e-01],\n",
       "          [1.6213e+00, 1.1085e+00, 6.7688e-01, 1.2306e+00, 1.3302e+00,\n",
       "           5.0111e-01],\n",
       "          [2.3441e+00, 1.8588e+00, 1.0260e+00, 1.5752e+00, 1.4789e+00,\n",
       "           1.2586e+00],\n",
       "          [3.1707e+00, 2.1309e+00, 1.7806e+00, 1.7663e+00, 1.8887e+00,\n",
       "           1.8118e+00],\n",
       "          [3.9721e+00, 2.8212e+00, 2.1134e+00, 2.6731e+00, 2.4088e+00,\n",
       "           2.2693e+00]]],\n",
       "\n",
       "\n",
       "        [[[5.7527e-01, 7.6890e-01, 2.2973e-01, 2.5378e-03, 7.5288e-01,\n",
       "           6.1307e-01],\n",
       "          [1.5227e+00, 1.0951e+00, 4.2301e-01, 2.3566e-01, 1.6570e+00,\n",
       "           6.3231e-01],\n",
       "          [2.0460e+00, 1.7412e+00, 9.6863e-01, 4.1995e-01, 2.0612e+00,\n",
       "           7.1157e-01],\n",
       "          [2.0471e+00, 1.9504e+00, 1.3492e+00, 1.1892e+00, 2.3306e+00,\n",
       "           1.5449e+00],\n",
       "          [2.1870e+00, 2.1231e+00, 1.9143e+00, 1.4981e+00, 3.1159e+00,\n",
       "           1.9219e+00]],\n",
       "\n",
       "         [[1.3034e-01, 9.1983e-01, 3.6165e-01, 3.7894e-01, 7.9992e-01,\n",
       "           8.6322e-01],\n",
       "          [7.2669e-01, 1.4267e+00, 8.8681e-01, 1.2067e+00, 8.0040e-01,\n",
       "           1.6582e+00],\n",
       "          [1.6850e+00, 2.0420e+00, 1.8148e+00, 1.5666e+00, 9.6843e-01,\n",
       "           2.3112e+00],\n",
       "          [1.7898e+00, 2.2407e+00, 1.9086e+00, 2.1498e+00, 1.9113e+00,\n",
       "           2.9863e+00],\n",
       "          [2.3424e+00, 2.9937e+00, 2.3946e+00, 2.3274e+00, 2.6236e+00,\n",
       "           3.9728e+00]],\n",
       "\n",
       "         [[2.9916e-01, 4.5821e-01, 8.4067e-01, 9.3575e-01, 5.1400e-01,\n",
       "           1.0528e-01],\n",
       "          [7.9125e-01, 1.1970e+00, 1.7265e+00, 1.5279e+00, 7.8610e-01,\n",
       "           8.7521e-01],\n",
       "          [1.0399e+00, 1.4982e+00, 2.2560e+00, 1.6320e+00, 8.5789e-01,\n",
       "           1.6121e+00],\n",
       "          [1.2300e+00, 2.4570e+00, 3.0316e+00, 1.6519e+00, 1.3674e+00,\n",
       "           1.6906e+00],\n",
       "          [1.7132e+00, 2.9423e+00, 3.2359e+00, 1.6801e+00, 1.7190e+00,\n",
       "           2.2445e+00]]]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.tril(torch.ones(2, 3, 5, 5)), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 0., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0.],\n",
       "          [1., 1., 1., 0., 0.],\n",
       "          [1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(2, 3, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
