{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "## data imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "## transformer related imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers_fmt.model_blocks.transformer import Transformers\n",
    "\n",
    "## constants\n",
    "from constants import ROOT_DIR, DEVICE\n",
    "from utils.logging import logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.add_special_tokens({\n",
    "    'bos_token' : '[BOS]',\n",
    "    'eos_token' : '[EOS]'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_location, chunksize=1000, n_chunks = 100) :\n",
    "\n",
    "    data = []\n",
    "\n",
    "\n",
    "    for i, items in enumerate(pd.read_csv(file_location, chunksize=chunksize)) :\n",
    "\n",
    "        data.append(items)\n",
    "        if i == n_chunks - 1 :\n",
    "            break\n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data.index = range(len(data))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(file_location=os.path.join(ROOT_DIR, 'data/en_fr_100K.csv'), n_chunks = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_sentence(max_seq_len, data):\n",
    "    \"\"\"\n",
    "    Remove sentences that are longer than max_seq_len\n",
    "    \"\"\"\n",
    "    data['en_sentence_length'] = data['en'].apply(lambda x : len(x.split()) if type(x) == str else max_seq_len + 1)\n",
    "    data['fr_sentence_length'] = data['fr'].apply(lambda x : len(x.split()) if type(x) == str else max_seq_len + 1)\n",
    "\n",
    "    data = data.drop(\n",
    "        data[(data['en_sentence_length'] > max_seq_len) | (data['fr_sentence_length'] > max_seq_len)].index\n",
    "    )\n",
    "\n",
    "    data.index = range(len(data))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_long_sentence(max_seq_len, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "      <th>en_sentence_length</th>\n",
       "      <th>fr_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is light ?</td>\n",
       "      <td>Qu’est-ce que la lumière?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10322</th>\n",
       "      <td>The three companies mentioned above supply ret...</td>\n",
       "      <td>Les trois firmes ci-haut approvisionnent les d...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10323</th>\n",
       "      <td>MAPAQ and AAC estimate, 2004.</td>\n",
       "      <td>MAPAQ et estimation d’AAC, 2004.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10324</th>\n",
       "      <td>Inevitably, this trend relating to bread’s app...</td>\n",
       "      <td>Inévitablement, ces deux tendances d’apparence...</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10325</th>\n",
       "      <td>Retail strategies… In Québec, concentration of...</td>\n",
       "      <td>Stratégies au détail… Au Québec, la concentrat...</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>Weston Foods subsidiary Ready Bake Foods Inc. ...</td>\n",
       "      <td>La filiale Ready Bake Foods Inc. de Weston Foo...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10327 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0                                               Site map   \n",
       "1                                               Feedback   \n",
       "2                                                Credits   \n",
       "3                                               Français   \n",
       "4                                        What is light ?   \n",
       "...                                                  ...   \n",
       "10322  The three companies mentioned above supply ret...   \n",
       "10323                      MAPAQ and AAC estimate, 2004.   \n",
       "10324  Inevitably, this trend relating to bread’s app...   \n",
       "10325  Retail strategies… In Québec, concentration of...   \n",
       "10326  Weston Foods subsidiary Ready Bake Foods Inc. ...   \n",
       "\n",
       "                                                      fr  en_sentence_length  \\\n",
       "0                                           Plan du site                   2   \n",
       "1                                            Rétroaction                   1   \n",
       "2                                                Crédits                   1   \n",
       "3                                                English                   1   \n",
       "4                              Qu’est-ce que la lumière?                   4   \n",
       "...                                                  ...                 ...   \n",
       "10322  Les trois firmes ci-haut approvisionnent les d...                  13   \n",
       "10323                   MAPAQ et estimation d’AAC, 2004.                   5   \n",
       "10324  Inévitablement, ces deux tendances d’apparence...                  19   \n",
       "10325  Stratégies au détail… Au Québec, la concentrat...                  13   \n",
       "10326  La filiale Ready Bake Foods Inc. de Weston Foo...                  18   \n",
       "\n",
       "       fr_sentence_length  \n",
       "0                       3  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       4  \n",
       "...                   ...  \n",
       "10322                  11  \n",
       "10323                   5  \n",
       "10324                  17  \n",
       "10325                  18  \n",
       "10326                  20  \n",
       "\n",
       "[10327 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data.index = range(len(train_data))\n",
    "val_data.index = range(len(val_data))\n",
    "test_data.index = range(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset) :\n",
    "\n",
    "    def __init__(self, data) :\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index) -> any:\n",
    "        row = self.data.loc[index]\n",
    "        return {'en' : row['en'], 'fr' : row['fr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch, type = 'input') :\n",
    "\n",
    "    ## Append the BOS and EOS token based on wether the batch is the encoder input, decoder input(output shifted left)\n",
    "    ## or the label (output shifted right)\n",
    "    if type == 'input' :\n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (\n",
    "                    torch.tensor([tokenizer.bos_token_id]), \n",
    "                    torch.tensor(inp), \n",
    "                    torch.tensor([tokenizer.eos_token_id])\n",
    "                ),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    elif type == 'output' :\n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (torch.tensor([tokenizer.bos_token_id]), torch.tensor(inp)),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    elif type == 'label' :\n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (torch.tensor(inp), torch.tensor([tokenizer.eos_token_id])),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    ## pad the token to the maxiumum sentence length\n",
    "    input_token_ids = pad_sequence(input_token_ids, batch_first=True, padding_value = tokenizer.pad_token_id)\n",
    "\n",
    "    return input_token_ids\n",
    "\n",
    "# def collate_fn(samples):\n",
    "    \n",
    "#     eng_samples = [items['en'] for items in samples]\n",
    "#     fr_samples = [items['fr'] for items in samples]\n",
    "\n",
    "#     batch = {}\n",
    "\n",
    "#     for language, sample in {'en' : eng_samples, 'fr' : fr_samples}.items() :\n",
    "\n",
    "#         sample = tokenizer.batch_encode_plus(sample)\n",
    "#         batch[language] = preprocess_batch(sample)\n",
    "\n",
    "#     # samples['fr'] = tokenizer.batch_encode_plus(samples['fr'])\n",
    "#     return batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "val_dataset = Data(val_data)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = Data(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "data_loaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader,\n",
    "    'test': test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformers(\n",
    "    n_layer = 6,\n",
    "    n_heads = 8,\n",
    "    d_model = 512, \n",
    "    d_ff = 2048,\n",
    "    max_seq_len = 512,\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    device = DEVICE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, enc_output, tokenizer, max_seq_len, device):\n",
    "    \n",
    "    input_ids = torch.tensor([[tokenizer.bos_token_id] for _ in range(enc_output.size(0))]).to(device)\n",
    "\n",
    "    unfinished_sequences = torch.ones(input_ids.size(0), 1).to(device)\n",
    "    eos_token_id_tensor = torch.tensor([tokenizer.eos_token_id]).to(device)\n",
    "    # logs('unfinished_sequences size: {}'.format(unfinished_sequences.size()), debug)\n",
    "\n",
    "    sentence_length = input_ids.size(1)\n",
    "\n",
    "    while sentence_length <= max_seq_len :\n",
    "\n",
    "        x = model.embedding(input_ids)\n",
    "        x = model.positonal_embedding(x)\n",
    "        x = model.decoder(x, enc_output)\n",
    "        next_token_logits = x[:, -1, :]\n",
    "        \n",
    "        # logs(f'next_token_logits size: {next_token_logits.size()}', debug)\n",
    "\n",
    "        next_token_logits = F.softmax(next_token_logits, dim=1)\n",
    "        next_token_indices = torch.argmax(next_token_logits, dim = 1)\n",
    "\n",
    "        # logs(f'next_token_indices post softmax size: {next_token_indices.size()}', debug)\n",
    "\n",
    "        # logs(f'next_token_indices * unfinished_sequences size: {(next_token_indices.unsqueeze(1) * unfinished_sequences).size()}', debug)\n",
    "\n",
    "        # logs(f'tokenizer.pad_token_id * (1 - unfinished_sequences) size: {(tokenizer.pad_token_id * (1 - unfinished_sequences)).size()}', debug)\n",
    "\n",
    "        next_token_indices = (\n",
    "            next_token_indices.unsqueeze(1) * unfinished_sequences + tokenizer.pad_token_id * (1 - unfinished_sequences)\n",
    "        )\n",
    "        unfinished_sequences = unfinished_sequences.mul(\n",
    "            next_token_indices.tile(\n",
    "                eos_token_id_tensor.shape[0]\n",
    "            ).ne(eos_token_id_tensor).prod(dim = 0)\n",
    "        )\n",
    "\n",
    "        if unfinished_sequences.max() == 0 :\n",
    "            break\n",
    "\n",
    "        # print(input_ids.size())\n",
    "        # print(next_token_indices.size())\n",
    "\n",
    "        input_ids = torch.cat(\n",
    "            (\n",
    "                input_ids, \n",
    "                next_token_indices\n",
    "            ), \n",
    "            dim = 1).long()\n",
    "\n",
    "        sentence_length += 1\n",
    "    \n",
    "        print(input_ids.size(1))\n",
    "\n",
    "    return input_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / val loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "def train_model(model, data_loader, optimizer, criterion, device, mode = 'train', verbose_interval = 100) :\n",
    "\n",
    "    EPOCH_LOSS = 0\n",
    "\n",
    "    assert mode in ['train', 'val'], 'Mode should be either \"train\" or \"val\"'\n",
    "\n",
    "    if mode == 'train' :\n",
    "        model.train()\n",
    "    elif mode == 'val' :\n",
    "        model.eval()\n",
    "\n",
    "    for i, rows in enumerate(data_loader[mode]) :\n",
    "\n",
    "        ## preprocess batch for training\n",
    "        en_token_ids = tokenizer.batch_encode_plus(rows['en'], add_special_tokens = False)\n",
    "        fr_token_ids = tokenizer.batch_encode_plus(rows['fr'], add_special_tokens = False)\n",
    "        encoder_inp = preprocess_batch(en_token_ids, type='input').to(device)\n",
    "        logs(f'encoder_inp size : {encoder_inp.size()}', debug)\n",
    "        decoder_inp = preprocess_batch(fr_token_ids, type='output').to(device)\n",
    "        logs(f'decoder_inp size : {decoder_inp.size()}', debug)\n",
    "        label = preprocess_batch(fr_token_ids, type='label').to(device)\n",
    "\n",
    "        ## forward pass through the model\n",
    "        attention_scores, output = model(encoder_inp, decoder_inp)\n",
    "\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, label.reshape(-1))\n",
    "\n",
    "        ## optimize model\n",
    "        if mode == 'train' :\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ## accumulate loss\n",
    "        EPOCH_LOSS += loss.item()\n",
    "\n",
    "        if i % verbose_interval == 0 :\n",
    "            print(f'{mode} step {i} | loss : {loss.item()}')\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return EPOCH_LOSS / len(data_loader[mode])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, valid_loader, device, tokenizer, max_seq_len) :\n",
    "\n",
    "    EPOCH_LOSS = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, rows in enumerate(valid_loader) :\n",
    "\n",
    "        ## preprocess batch for training\n",
    "        en_token_ids = tokenizer.batch_encode_plus(rows['en'], add_special_tokens = False)\n",
    "        fr_token_ids = tokenizer.batch_encode_plus(rows['fr'], add_special_tokens = False)\n",
    "        encoder_inp = preprocess_batch(en_token_ids, type='input').to(device)\n",
    "        decoder_inp = preprocess_batch(fr_token_ids, type='output').to(device)\n",
    "        label = preprocess_batch(fr_token_ids, type='label').to(device)\n",
    "\n",
    "        ## encode the input\n",
    "        enc_output, attention_scores = model.encoder_pass(encoder_inp)\n",
    "\n",
    "        \n",
    "        input_tokens = generate(model, enc_output, tokenizer, max_seq_len)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.614755403537017"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_val_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 11\n",
      "train step 0 | loss : 2.2534258365631104\n",
      "train step 100 | loss : 2.4846417903900146\n",
      "train step 200 | loss : 2.237774133682251\n",
      "train step 300 | loss : 2.2333824634552\n",
      "train step 400 | loss : 2.823529005050659\n",
      "train step 500 | loss : 2.783541202545166\n",
      "train step 600 | loss : 3.073777198791504\n",
      "train step 700 | loss : 1.8134424686431885\n",
      "train step 800 | loss : 2.9789955615997314\n",
      "train step 900 | loss : 3.219877243041992\n",
      "train step 1000 | loss : 2.028871536254883\n",
      "val step 0 | loss : 3.359246015548706\n",
      "val step 100 | loss : 2.549464225769043\n",
      "Epochs : 11 | Train Loss : 2.4515 | Val Loss : 2.3723\n",
      "----------------------------------------------------\n",
      "Epochs 12\n",
      "train step 0 | loss : 2.0949904918670654\n",
      "train step 100 | loss : 1.9420729875564575\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = os.path.join(ROOT_DIR, 'model_weights')\n",
    "start_epochs = 10\n",
    "end_epochs = 100\n",
    "\n",
    "for epochs in range(start_epochs, end_epochs) :\n",
    "\n",
    "    print(f'Epochs {epochs + 1}')\n",
    "\n",
    "    train_loss = train_model(model, data_loaders, optimizer, criterion, DEVICE, mode = 'train')\n",
    "    val_loss = train_model(model, data_loaders, optimizer, criterion, DEVICE, mode = 'val')\n",
    "    \n",
    "    if val_loss < least_val_loss :\n",
    "        least_val_loss = val_loss\n",
    "        torch.save(\n",
    "            model.state_dict(), \n",
    "            os.path.join(MODEL_DIR, f'transformer_ep-{epochs + 1}_val-loss-{val_loss:.4f}.pt')\n",
    "        )\n",
    "\n",
    "    print(f'Epochs : {epochs + 1} | Train Loss : {train_loss:.4f} | Val Loss : {val_loss:.4f}')\n",
    "    print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = ['my name is kong', 'this is aditya rustagi', 'i like to eat ice cream']\n",
    "test_sentence_tokens = tokenizer.batch_encode_plus(test_sentence, add_special_tokens = False)\n",
    "encoder_inp = preprocess_batch(test_sentence_tokens, type='input').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "enc_output, attention_scores = model.encoder_pass(encoder_inp)\n",
    "output_ids = generate(model, enc_output, tokenizer, max_seq_len, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS] Æ \\\\ Â s [unused67] \\\\ | Â 5 å [unused87] å [unused87] 5 ̍ [unused87] 5 В Œ |',\n",
       " '[BOS] ť s Ό å σ å [unused94] å [unused94] å [unused94] å [unused94] å [unused94] | Â 5 å å',\n",
       " '[BOS] Æ s Ό Â \\\\ Â | Â Τ [unused97] | Â 5 5 В Œ | Â 5 5']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
