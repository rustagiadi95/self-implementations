{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityarustagi/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "## data imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## transformer related imports\n",
    "from transformers import AutoTokenizer\n",
    "from transformers_fmt.model_blocks.transformer import Transformers\n",
    "\n",
    "## constants\n",
    "from constants import ROOT_DIR, DEVICE, LOGS_DIR\n",
    "from utils.logging import logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6, 9, 5, 3, 1, 5, 5, 6, 7, 4, 7, 9],\n",
       "         [3, 8, 6, 3, 9, 1, 3, 2, 7, 2, 2, 7],\n",
       "         [5, 4, 8, 9, 9, 7, 1, 2, 4, 4, 8, 1]],\n",
       "\n",
       "        [[1, 2, 1, 1, 9, 7, 1, 9, 8, 4, 4, 4],\n",
       "         [3, 3, 3, 4, 4, 9, 7, 2, 8, 1, 9, 3],\n",
       "         [6, 3, 8, 4, 8, 3, 4, 6, 6, 2, 1, 3]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = torch.randint(1, 10, (2, 3, 12))\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_tensor = torch.stack(keys.split(3, dim = 2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6, 9, 5, 3, 1, 5, 5, 6, 7, 4, 7, 9],\n",
       "         [3, 8, 6, 3, 9, 1, 3, 2, 7, 2, 2, 7],\n",
       "         [5, 4, 8, 9, 9, 7, 1, 2, 4, 4, 8, 1]],\n",
       "\n",
       "        [[1, 2, 1, 1, 9, 7, 1, 9, 8, 4, 4, 4],\n",
       "         [3, 3, 3, 4, 4, 9, 7, 2, 8, 1, 9, 3],\n",
       "         [6, 3, 8, 4, 8, 3, 4, 6, 6, 2, 1, 3]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat(splitted_tensor.split(split_size=1, dim = 0), dim=3).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs dir for current run: /Users/adityarustagi/Documents/self-implementations/logs/transformer_2023-08-13_16:53:47\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 20\n",
    "logs_dir = os.path.join(LOGS_DIR, f'transformer_{datetime.strftime(datetime.now(), \"%Y-%m-%d_%H:%M:%S\")}')\n",
    "print(f'Logs dir for current run: {logs_dir}')\n",
    "writer = SummaryWriter(log_dir=logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### SELF IMPLEMENTATIONS ######################################\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module) :\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 mask: bool = False,\n",
    "                 device: str = 'cuda',\n",
    "        ) -> None :\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_heads (int): Number of heads in the multi head attention. Defualts to 8\n",
    "            d_model (int, optional): Dimension of the input. Defaults to 512.\n",
    "            mask (bool, optional): Whether to apply masking. Defaults to False\n",
    "        \"\"\"\n",
    "\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.mask = mask\n",
    "        self.d_k = int(d_model/n_heads)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,\n",
    "                key : torch.Tensor,\n",
    "                query : torch.Tensor,\n",
    "                value : torch.Tensor,\n",
    "                encoder_mask : torch.Tensor = None\n",
    "        ) -> torch.Tensor :\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate scaler dot product of key, query and values as described in https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "        Args:\n",
    "            key (torch.Tensor): Key tensor. Shape = (n_heads, batch_size, seq_len, d_model/n_heads)\n",
    "            query (torch.Tensor): Query tensor. Shape = (n_heads, batch_size, seq_len, d_model/n_heads)\n",
    "            value (torch.Tensor): Value tensor. Shape = (n_heads, batch_size, seq_len, d_model/n_heads)\n",
    "            encoder_mask (torch.Tensor): Mask applied to attention to make softmax scores of [PAD] token 0. Defaults to None\n",
    "\n",
    "        Returns:\n",
    "            value_with_attention: Value with attention applied. Shape = (n_heads, batch_size, seq_len, d_model/n_heads)\n",
    "        \"\"\"\n",
    "\n",
    "        # assert key.size() == query.size() == value.size(), \"Key, query and value must have same shape\"\n",
    "\n",
    "        batch_size, seq_len = key.size(1), key.size(2)\n",
    "        attention_scores = torch.matmul(query, key.transpose(2, 3))/torch.sqrt(torch.tensor(self.d_k))\n",
    "\n",
    "        if encoder_mask is not None:\n",
    "            attention_scores = torch.masked_fill(\n",
    "                                    attention_scores, \n",
    "                                    encoder_mask.unsqueeze(1) == False,\n",
    "                                    float('-inf')\n",
    "                                )\n",
    "        \n",
    "        if self.mask :\n",
    "            seq_len_enc = attention_scores.size(2)\n",
    "            seq_len_dec = attention_scores.size(3)\n",
    "            attention_scores = torch.masked_fill(\n",
    "                                    attention_scores, \n",
    "                                    torch.tril(torch.ones(seq_len_enc, seq_len_dec)).to(self.device) == False, \n",
    "                                    float('-inf')\n",
    "                                )\n",
    "\n",
    "        attention_scores = torch.softmax(attention_scores, dim = 3)\n",
    "            \n",
    "        value_with_attention = torch.matmul(attention_scores, value)\n",
    "\n",
    "        return value_with_attention, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdpa = ScaledDotProductAttention(\n",
    "    d_model = 10,\n",
    "    mask=False,\n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = torch.rand((2, 3, 4, 5))\n",
    "query = torch.rand((2, 3, 4, 5))\n",
    "value = torch.rand((2, 3, 4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_mask = torch.tensor(\n",
    "    [\n",
    "        [1, 1, 0, 0],\n",
    "        [1, 1, 1, 0],\n",
    "        [1, 1, 1, 1]\n",
    "    ]\n",
    ")# encoder_mask = torch.randint(0, 2, (2, 3, 4, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_with_attention, attention_scores=sdpa(key, query, value, encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3770, 0.6230, 0.0000, 0.0000],\n",
       "          [0.3160, 0.6840, 0.0000, 0.0000],\n",
       "          [0.3861, 0.6139, 0.0000, 0.0000],\n",
       "          [0.5343, 0.4657, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2710, 0.4216, 0.3073, 0.0000],\n",
       "          [0.3710, 0.3755, 0.2536, 0.0000],\n",
       "          [0.2850, 0.4102, 0.3048, 0.0000],\n",
       "          [0.2552, 0.4704, 0.2744, 0.0000]],\n",
       "\n",
       "         [[0.2327, 0.1993, 0.0953, 0.4727],\n",
       "          [0.3091, 0.2113, 0.1598, 0.3198],\n",
       "          [0.2925, 0.1383, 0.1051, 0.4641],\n",
       "          [0.2077, 0.1533, 0.1367, 0.5023]]],\n",
       "\n",
       "\n",
       "        [[[0.6433, 0.3567, 0.0000, 0.0000],\n",
       "          [0.5522, 0.4478, 0.0000, 0.0000],\n",
       "          [0.5094, 0.4906, 0.0000, 0.0000],\n",
       "          [0.4833, 0.5167, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2996, 0.2577, 0.4427, 0.0000],\n",
       "          [0.3451, 0.3384, 0.3165, 0.0000],\n",
       "          [0.3068, 0.3937, 0.2995, 0.0000],\n",
       "          [0.3383, 0.4003, 0.2615, 0.0000]],\n",
       "\n",
       "         [[0.2144, 0.2596, 0.3001, 0.2259],\n",
       "          [0.2686, 0.2147, 0.2485, 0.2682],\n",
       "          [0.2888, 0.2140, 0.2387, 0.2586],\n",
       "          [0.2383, 0.2548, 0.3021, 0.2048]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### MULTI HEADED ATTENTION ######################################\n",
    "\n",
    "class MultiHeadAttention(nn.Module) :\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_head: int = 8, \n",
    "                 d_model: int = 512, \n",
    "                 dropout: float = 0.1, \n",
    "                 mask: bool = False,\n",
    "                 self_attention: bool = True,\n",
    "                 device: str = 'cuda',\n",
    "        ) :\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_head (int): Number of heads. Defaults to 8.\n",
    "            d_model (int): Dimension of input. Defaults to 512.\n",
    "            dropout (float): Dropout rate. Defaults to 0.1.\n",
    "            mask (bool): Whether to mask the attention. Defaults to False.\n",
    "            self_attention (bool): Whether to use self attention. Defaults to True.\n",
    "        \"\"\"\n",
    "\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.self_attention = self_attention\n",
    "\n",
    "        self.d_k = self.d_v = d_model // n_head\n",
    "        self.w_qs = nn.Linear(d_model, n_head * self.d_k)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * self.d_k)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * self.d_v)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(n_head, d_model, mask, device = device)\n",
    "\n",
    "        self.mha_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        nn.init.normal_(self.w_qs.weight, mean = 0, std = np.sqrt(2.0 / (d_model + self.d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean = 0, std = np.sqrt(2.0 / (d_model + self.d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean = 0, std = np.sqrt(2.0 / (d_model + self.d_v)))\n",
    "\n",
    "    def forward(self, x, encoder_mask = None, q = None) :\n",
    "\n",
    "        \"\"\"\n",
    "        Implementation of multi head attention layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Padded input with the shaep batch_len, seq_len, d_model\n",
    "            q (torch.Tensor): Query with the shape batch_size, seq_len, d_model. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Values with multiheadattention applied. Shape = (batch_size, seq_len, d_model)\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If mode is cross attention and query passed in forward is None.\n",
    "            ValueError: If mode is cross attention and shape of query is not same as input coming from encoder.\n",
    "        \n",
    "        References:\n",
    "            https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/MultiHeadAttention.py\n",
    "            https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Transformer.py\n",
    "            https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/PositionalEncoding.py\n",
    "        \"\"\"\n",
    "         \n",
    "        if not self.self_attention:\n",
    "            if q is None :\n",
    "                raise ValueError(\"q is required for cross attention\")\n",
    "            # elif x.size() != q.size() :\n",
    "            #     raise ValueError(\"q and X must have same size\")\n",
    "        else :\n",
    "            q = x\n",
    "\n",
    "        key = F.gelu(self.w_ks(x))\n",
    "        query = F.gelu(self.w_qs(q))\n",
    "        value = F.gelu(self.w_vs(x))\n",
    "\n",
    "        ## keeping n_heads as major dimension\n",
    "        key = torch.stack(key.split(self.d_k, dim = 2), dim=0)\n",
    "        query = torch.stack(query.split(self.d_k, dim = 2), dim=0)#query.view(-1, query.size(0), query.size(1), self.d_k)\n",
    "        value = torch.stack(value.split(self.d_k, dim = 2), dim=0)#value.view(-1, value.size(0), value.size(1), self.d_v)\n",
    "\n",
    "        value, attention = self.attention(key, query, value, encoder_mask)\n",
    "\n",
    "        value = torch.concat(value.split(split_size=1, dim = 0), dim=3).squeeze()\n",
    "\n",
    "        value = self.dropout(F.gelu(self.mha_linear(value)))\n",
    "\n",
    "        return value, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### ADD LAYER NORMALIZATION ######################################\n",
    "\n",
    "class AddLayerNormalization(nn.Module) :\n",
    "\n",
    "    def __init__(self, d_model) :\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm([d_model])\n",
    "\n",
    "    def forward(self, x, mha_output) :\n",
    "        \n",
    "        return self.layer_norm(x + mha_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### POINT-WISE FEED FORWARD ######################################\n",
    "\n",
    "class PointWiseFeedforward(nn.Module) :\n",
    "\n",
    "    def __init__(self, \n",
    "                 d_ff: int = 2048, \n",
    "                 d_model: int = 512\n",
    "    ) -> None :\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_ff (int): Intermediate size of the feedforward layer.\n",
    "            d_model (int):  Size of the embeddings.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(PointWiseFeedforward, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        \n",
    "        linear1_output = self.linear1(x)\n",
    "        linear2_output = self.linear2(F.gelu(linear1_output))\n",
    "\n",
    "        return linear2_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Transformer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### SINGLE ENCODER LAYER ######################################\n",
    "\n",
    "class EncoderLayer(nn.Module) :\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 d_ff: int = 2048,\n",
    "                 device: str = 'cuda'\n",
    "        ) -> None :\n",
    "        \n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(n_heads, d_model, device = device)\n",
    "        self.layer_norm = AddLayerNormalization(d_model)\n",
    "        self.pff = PointWiseFeedforward(d_ff, d_model)\n",
    "        self.layer_norm2 = AddLayerNormalization(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_mask) :\n",
    "\n",
    "        mha_output, mha_attention_scores = self.mha(x, encoder_mask=encoder_mask)\n",
    "        # logs(f\"mha_output shape: {mha_output.shape}\")\n",
    "        norm_output1 = self.layer_norm(x, mha_output)\n",
    "        # logs(f\"norm_output1 shape: {norm_output1.shape}\")\n",
    "\n",
    "        pff_output = self.pff(norm_output1)\n",
    "        # logs(f\"pff_output shape: {pff_output.shape}\")\n",
    "        norm_output2 = self.layer_norm2(norm_output1, pff_output)\n",
    "        # logs(f\"norm_output2 shape: {norm_output2.shape}\")\n",
    "\n",
    "        return norm_output2, mha_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### SINGLE DECODER LAYER ######################################\n",
    "\n",
    "class DecoderLayer(nn.Module) :\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_heads,\n",
    "                 d_model,\n",
    "                 d_ff, \n",
    "                 device\n",
    "    ) -> None :\n",
    "\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(n_heads, d_model, mask = True, device = device)\n",
    "        self.cross_mha = MultiHeadAttention(n_heads, d_model, self_attention=False, device = device)\n",
    "        self.layer_norm1 = AddLayerNormalization(d_model)\n",
    "        self.layer_norm2 = AddLayerNormalization(d_model)\n",
    "        self.layer_norm3 = AddLayerNormalization(d_model)\n",
    "        self.pff = PointWiseFeedforward(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x, encoder_out, encoder_mask) :\n",
    "        ## passing encoder output to all decoder layers : to be discussed with Deepak\n",
    "        decoder_query, _ = self.mha(x)\n",
    "        norm_decoder_query = self.layer_norm1(x, decoder_query)\n",
    "\n",
    "        x, _ = self.cross_mha(encoder_out, q = norm_decoder_query, encoder_mask=encoder_mask)\n",
    "        norm_cross_x = self.layer_norm2(norm_decoder_query, x)\n",
    "\n",
    "        x = self.pff(norm_cross_x)\n",
    "        norm_decoder_output = self.layer_norm3(norm_cross_x, x)\n",
    "\n",
    "        return norm_decoder_output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### POSITION EMBEDDING ######################################\n",
    "\n",
    "class PositionEmbedding(nn.Module) :\n",
    "\n",
    "    def __init__(self,\n",
    "        max_seq_len: int = 128, \n",
    "        d_model: int = 512,\n",
    "        dropout: int = 0.1,\n",
    "        device: str = 'cuda'\n",
    "    ) :\n",
    "\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "\n",
    "        self.embedding = torch.zeros(max_seq_len, d_model).to(device)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        for i in range(max_seq_len) :\n",
    "            self.embedding[i, 0::2] = torch.sin((i/1000**(2*torch.arange(d_model)[::2]/d_model)))\n",
    "            self.embedding[i, 1::2] = torch.cos((i/1000**(2*torch.arange(d_model)[1::2]/d_model)))\n",
    "\n",
    "    def forward(self, x) :\n",
    "\n",
    "        embedding = torch.repeat_interleave(self.embedding.unsqueeze(0), x.size(0), 0)\n",
    "\n",
    "        return self.dropout(x + embedding[:, :x.size(1), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### ENCODER ######################################\n",
    "\n",
    "class Encoder(nn.Module) :\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_layer: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 d_ff: int = 2048,\n",
    "                 device: str = 'cuda'\n",
    "    ) :\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.ModuleDict({\n",
    "            f'encoder_layer_{i}' : \n",
    "            (\n",
    "                EncoderLayer(\n",
    "                    n_heads,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    device = device\n",
    "                )\n",
    "            ) for i in range(n_layer)\n",
    "            })\n",
    "\n",
    "    def forward(self, x, encoder_mask) :\n",
    "        # logs(f'input size : {x.size()}')\n",
    "        for name, layer in self.encoder.items() :\n",
    "            x, attention_scores = layer(x, encoder_mask)\n",
    "            # logs(f'{name} output size : {x.size()}')\n",
    "        return x, attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### DECODER ######################################\n",
    "\n",
    "class Decoder(nn.Module) :\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_layer: int = 6,\n",
    "                 n_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 d_ff: int = 2048,\n",
    "                 device: str = 'cuda'\n",
    "    ) -> None :\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = nn.ModuleDict({\n",
    "            f'decoder_layer_{i}' :\n",
    "            (\n",
    "                DecoderLayer(\n",
    "                    n_heads,\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    device = device\n",
    "                )\n",
    "            ) for i in range(n_layer)\n",
    "        })\n",
    "\n",
    "\n",
    "    def forward(self, x, encoder_out, encoder_mask) :\n",
    "\n",
    "        for name, layer in self.decoder.items() :\n",
    "            x = layer(x, encoder_out, encoder_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### TRANSFORMER_FMT ######################################\n",
    "\n",
    "class Transformers(nn.Module) :\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_layer,\n",
    "                 n_heads,\n",
    "                 d_model,\n",
    "                 d_ff,\n",
    "                 max_seq_len,\n",
    "                 vocab_size,\n",
    "                 device\n",
    "        ) -> None :\n",
    "\n",
    "        super(Transformers, self).__init__()\n",
    "\n",
    "        vocab_size = vocab_size + 2\n",
    "\n",
    "        self.encoder = Encoder(n_layer, n_heads, d_model, d_ff, device=device)\n",
    "        self.decoder = Decoder(n_layer, n_heads, d_model, d_ff, device=device)\n",
    "        self.positonal_embedding = PositionEmbedding(max_seq_len, d_model, device=device)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.logit_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "\n",
    "    def encoder_pass(self, x, encoder_mask) :\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.positonal_embedding(x)\n",
    "        x = self.encoder(x, encoder_mask)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def decoder_pass(self, encoder_output, input_ids, encoder_mask) :\n",
    "\n",
    "        x = self.embedding(input_ids)\n",
    "        x = self.positonal_embedding(x)\n",
    "        x = self.decoder(x, encoder_output, encoder_mask)\n",
    "\n",
    "        next_token_logits = F.relu(self.logit_layer(x))\n",
    "        next_token_logits = next_token_logits.reshape(-1, next_token_logits.size(2))\n",
    "\n",
    "        return F.log_softmax(next_token_logits, dim=1)\n",
    "\n",
    "    def forward(self, encoder_inp, decoder_inp, encoder_mask) :\n",
    "\n",
    "        enc_output, attention_scores = self.encoder_pass(encoder_inp, encoder_mask)\n",
    "        output = self.decoder_pass(enc_output, decoder_inp, encoder_mask)\n",
    "\n",
    "        return attention_scores, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.add_special_tokens({\n",
    "    'bos_token' : '[BOS]',\n",
    "    'eos_token' : '[EOS]'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_location, chunksize=1000, n_chunks = 100) :\n",
    "\n",
    "    data = []\n",
    "\n",
    "\n",
    "    for i, items in enumerate(pd.read_csv(file_location, chunksize=chunksize)) :\n",
    "\n",
    "        data.append(items)\n",
    "        if i == n_chunks - 1 :\n",
    "            break\n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data.index = range(len(data))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(file_location=os.path.join(ROOT_DIR, 'data/en_fr_100K.csv'), n_chunks = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_sentence(max_seq_len, data):\n",
    "    \"\"\"\n",
    "    Remove sentences that are longer than max_seq_len\n",
    "    \"\"\"\n",
    "    data['en_sentence_length'] = data['en'].apply(lambda x : len(x.split()) if type(x) == str else max_seq_len + 1)\n",
    "    data['fr_sentence_length'] = data['fr'].apply(lambda x : len(x.split()) if type(x) == str else max_seq_len + 1)\n",
    "\n",
    "    data = data.drop(\n",
    "        data[(data['en_sentence_length'] > max_seq_len) | (data['fr_sentence_length'] > max_seq_len)].index\n",
    "    )\n",
    "\n",
    "    data.index = range(len(data))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_long_sentence(max_seq_len, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "      <th>en_sentence_length</th>\n",
       "      <th>fr_sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Site map</td>\n",
       "      <td>Plan du site</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>Rétroaction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credits</td>\n",
       "      <td>Crédits</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Français</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is light ?</td>\n",
       "      <td>Qu’est-ce que la lumière?</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Bubble Are we almost there?</td>\n",
       "      <td>Bulle Quand est-ce qu’on arrive?</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Bubble I’m hungry.</td>\n",
       "      <td>Bulle J’ai faim.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Sound  Car Image 3 Mother  Stop pestering your...</td>\n",
       "      <td>Bruit Voiture Image 3 Mère Laissez votre père ...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>We’re almost there… aren’t we?</td>\n",
       "      <td>Nous ne sommes plus très loin (en regardant so...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Girl  Why are we going to spend our vacation i...</td>\n",
       "      <td>Fillette Je me demande pourquoi on va passer d...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    en  \\\n",
       "0                                             Site map   \n",
       "1                                             Feedback   \n",
       "2                                              Credits   \n",
       "3                                             Français   \n",
       "4                                      What is light ?   \n",
       "..                                                 ...   \n",
       "988                        Bubble\n",
       "Are we almost there?   \n",
       "989                                 Bubble\n",
       "I’m hungry.   \n",
       "990  Sound \n",
       "Car Image 3 Mother \n",
       "Stop pestering your...   \n",
       "991                     We’re almost there… aren’t we?   \n",
       "992  Girl \n",
       "Why are we going to spend our vacation i...   \n",
       "\n",
       "                                                    fr  en_sentence_length  \\\n",
       "0                                         Plan du site                   2   \n",
       "1                                          Rétroaction                   1   \n",
       "2                                              Crédits                   1   \n",
       "3                                              English                   1   \n",
       "4                            Qu’est-ce que la lumière?                   4   \n",
       "..                                                 ...                 ...   \n",
       "988                   Bulle\n",
       "Quand est-ce qu’on arrive?                   5   \n",
       "989                                   Bulle\n",
       "J’ai faim.                   3   \n",
       "990  Bruit\n",
       "Voiture Image 3 Mère\n",
       "Laissez votre père ...                  10   \n",
       "991  Nous ne sommes plus très loin (en regardant so...                   5   \n",
       "992  Fillette\n",
       "Je me demande pourquoi on va passer d...                  15   \n",
       "\n",
       "     fr_sentence_length  \n",
       "0                     3  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     4  \n",
       "..                  ...  \n",
       "988                   5  \n",
       "989                   3  \n",
       "990                   9  \n",
       "991                  12  \n",
       "992                  16  \n",
       "\n",
       "[993 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data.index = range(len(train_data))\n",
    "val_data.index = range(len(val_data))\n",
    "test_data.index = range(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset) :\n",
    "\n",
    "    def __init__(self, data) :\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index) -> any:\n",
    "        row = self.data.loc[index]\n",
    "        return {'en' : row['en'], 'fr' : row['fr']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Data(train_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "val_dataset = Data(val_data)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = Data(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "data_loaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader,\n",
    "    'test': test_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformers(\n",
    "    n_layer = 6,\n",
    "    n_heads = 8,\n",
    "    d_model = 512,\n",
    "    d_ff = 2048,\n",
    "    max_seq_len = 512,\n",
    "    vocab_size = tokenizer.vocab_size,\n",
    "    device = DEVICE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(batch, type = 'input') :\n",
    "\n",
    "    ## Append the BOS and EOS token based on wether the batch is the encoder input, decoder input(output shifted left)\n",
    "    ## or the label (output shifted right)\n",
    "    if type == 'input' :\n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (torch.tensor([tokenizer.bos_token_id]), torch.tensor(inp), torch.tensor([tokenizer.eos_token_id])),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    elif type == 'output' :\n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (torch.tensor([tokenizer.bos_token_id]), torch.tensor(inp)),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    elif type == 'label' :\n",
    "        \n",
    "        input_token_ids = [\n",
    "            torch.cat(\n",
    "                (torch.tensor(inp), torch.tensor([tokenizer.eos_token_id])),\n",
    "            ) for inp in batch['input_ids']\n",
    "        ]\n",
    "\n",
    "    ## pad the token to the maxiumum sentence length\n",
    "    input_token_ids = pad_sequence(input_token_ids, batch_first=True, padding_value = tokenizer.pad_token_id, )\n",
    "\n",
    "    return input_token_ids\n",
    "\n",
    "# def collate_fn(samples):\n",
    "    \n",
    "#     eng_samples = [items['en'] for items in samples]\n",
    "#     fr_samples = [items['fr'] for items in samples]\n",
    "\n",
    "#     batch = {}\n",
    "\n",
    "#     for language, sample in {'en' : eng_samples, 'fr' : fr_samples}.items() :\n",
    "\n",
    "#         sample = tokenizer.batch_encode_plus(sample)\n",
    "#         batch[language] = preprocess_batch(sample)\n",
    "\n",
    "#     # samples['fr'] = tokenizer.batch_encode_plus(samples['fr'])\n",
    "#     return batch  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / val loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "debug = False\n",
    "\n",
    "def train_model(model, data_loader, optimizer, criterion, device, epoch, mode = 'train') :\n",
    "\n",
    "    EPOCH_LOSS = 0\n",
    "\n",
    "    assert mode in ['train', 'val'], 'Mode should be either \"train\" or \"val\"'\n",
    "\n",
    "    if mode == 'train' :\n",
    "        model.train()\n",
    "    elif mode == 'val' :\n",
    "        model.eval()\n",
    "\n",
    "    for i, rows in tqdm(enumerate(data_loader[mode]), total = len(data_loader[mode])) :\n",
    "\n",
    "        # try :\n",
    "\n",
    "        ## preprocess batch for training\n",
    "        en_token_ids = tokenizer.batch_encode_plus(rows['en'], add_special_tokens = False)\n",
    "        fr_token_ids = tokenizer.batch_encode_plus(rows['fr'], add_special_tokens = False)\n",
    "        encoder_inp = preprocess_batch(en_token_ids, type='input').to(device)\n",
    "        # print(encoder_inp.size())\n",
    "        logs(f'encoder_inp size : {encoder_inp.size()}', debug)\n",
    "        decoder_inp = preprocess_batch(fr_token_ids, type='output').to(device)\n",
    "        # print(decoder_inp.size())\n",
    "        logs(f'decoder_inp size : {decoder_inp.size()}', debug)\n",
    "        label = preprocess_batch(fr_token_ids, type='label').to(device)\n",
    "        # print(label.size())\n",
    "\n",
    "        ## encoder mask\n",
    "        enc_mask = encoder_inp != tokenizer.pad_token_id\n",
    "        enc_mask = enc_mask.long()\n",
    "\n",
    "        dec_mask = decoder_inp != tokenizer.pad_token_id\n",
    "        dec_mask = dec_mask.long()\n",
    "        # print(enc_mask.size())\n",
    "        \n",
    "        ## forward pass through the model\n",
    "        attention_scores, output = model(encoder_inp, decoder_inp, enc_mask)\n",
    "        # print(output.size())\n",
    "        # print(label.size())\n",
    "        ## calculate loss\n",
    "        loss = criterion(output, label.reshape(-1)) * dec_mask.reshape(-1).float()\n",
    "        loss = loss.sum() / dec_mask.reshape(-1).float().sum()\n",
    "\n",
    "        ## optimize model\n",
    "        if mode == 'train' :\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        ## accumulate loss\n",
    "        EPOCH_LOSS += loss.item()\n",
    "\n",
    "        writer.add_scalar(f'{mode} loss', EPOCH_LOSS/(i + 1), epoch * len(data_loader[mode]) + i)\n",
    "\n",
    "        # except Exception as e :\n",
    "        #     print(f'{epoch}_{i} | Exception : {e}')\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return EPOCH_LOSS / len(data_loader[mode])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_val_loss = 1000\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:42<00:00,  4.03s/it]\n",
      "100%|██████████| 13/13 [00:18<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Problem in saving model\n",
      "Exception : [Errno 2] No such file or directory: '/Users/adityarustagi/Documents/self-implementations/model_weights/transformer_ep-1_val-loss-8.5930.pt'\n",
      "Epochs : 1 | Train Loss : 9.5370 | Val Loss : 8.5930\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [04:12<03:02,  4.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m end_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epochs \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epochs, end_epochs) :\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[39m=\u001b[39m train_model(model, data_loaders, optimizer, criterion, DEVICE, epochs, mode \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# break\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     val_loss \u001b[39m=\u001b[39m train_model(model, data_loaders, optimizer, criterion, DEVICE, epochs, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[118], line 50\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, optimizer, criterion, device, epoch, mode)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m :\n\u001b[1;32m     49\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 50\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     51\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     53\u001b[0m \u001b[39m## accumulate loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_epochs = 0\n",
    "end_epochs = 100\n",
    "\n",
    "for epochs in range(start_epochs, end_epochs) :\n",
    "\n",
    "    train_loss = train_model(model, data_loaders, optimizer, criterion, DEVICE, epochs, mode = 'train')\n",
    "    # break\n",
    "    val_loss = train_model(model, data_loaders, optimizer, criterion, DEVICE, epochs, mode = 'val')\n",
    "    \n",
    "    if val_loss < least_val_loss :\n",
    "        try :\n",
    "            least_val_loss = val_loss\n",
    "            torch.save(\n",
    "                model.state_dict(), \n",
    "                os.path.join(MODEL_DIR, f'transformer_ep-{epochs + 1}_val-loss-{val_loss:.4f}.pt')\n",
    "            )\n",
    "        except Exception as e :\n",
    "            print(f'{epochs} | Problem in saving model\\nException : {e}')\n",
    "\n",
    "    print(f'Epochs : {epochs + 1} | Train Loss : {train_loss:.4f} | Val Loss : {val_loss:.4f}')\n",
    "    print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, valid_loader, device, tokenizer, max_seq_len) :\n",
    "\n",
    "    EPOCH_LOSS = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, rows in enumerate(valid_loader) :\n",
    "\n",
    "        ## preprocess batch for training\n",
    "        en_token_ids = tokenizer.batch_encode_plus(rows['en'], add_special_tokens = False)\n",
    "        fr_token_ids = tokenizer.batch_encode_plus(rows['fr'], add_special_tokens = False)\n",
    "        encoder_inp = preprocess_batch(en_token_ids, type='input').to(device)\n",
    "        decoder_inp = preprocess_batch(fr_token_ids, type='output').to(device)\n",
    "        label = preprocess_batch(fr_token_ids, type='label').to(device)\n",
    "        \n",
    "\n",
    "        ## encode the input\n",
    "        enc_output, attention_scores = model.encoder_pass(encoder_inp)\n",
    "\n",
    "        input_tokens = generate(model, enc_output, tokenizer, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "def generate(model, enc_output, tokenizer, max_seq_len, device):\n",
    "    \n",
    "    input_ids = torch.tensor([[tokenizer.bos_token_id] for _ in range(enc_output.size(0))]).to(device)\n",
    "\n",
    "    unfinished_sequences = torch.ones(input_ids.size(0), 1).to(device)\n",
    "    eos_token_id_tensor = torch.tensor([tokenizer.eos_token_id]).to(device)\n",
    "    # logs('unfinished_sequences size: {}'.format(unfinished_sequences.size()), debug)\n",
    "\n",
    "    sentence_length = input_ids.size(1)\n",
    "\n",
    "    while sentence_length <= max_seq_len :\n",
    "\n",
    "        x = model.embedding(input_ids)\n",
    "        x = model.positonal_embedding(x)\n",
    "        x = model.decoder(x, enc_output, encoder_mask = None)\n",
    "        next_token_logits = x[:, -1, :]\n",
    "        \n",
    "        logs(f'next_token_logits size: {next_token_logits.size()}', debug)\n",
    "        # print(next_token_logits)\n",
    "        next_token_logits = F.softmax(next_token_logits, dim=1)\n",
    "        next_token_indices = torch.argmax(next_token_logits, dim = 1)\n",
    "        print(next_token_indices)\n",
    "\n",
    "        logs(f'next_token_indices post softmax size: {next_token_indices.size()}', debug)\n",
    "\n",
    "        logs(f'next_token_indices * unfinished_sequences size: {(next_token_indices.unsqueeze(1) * unfinished_sequences).size()}', debug)\n",
    "\n",
    "        logs(f'tokenizer.pad_token_id * (1 - unfinished_sequences) size: {(tokenizer.pad_token_id * (1 - unfinished_sequences)).size()}', debug)\n",
    "\n",
    "        next_token_indices = (\n",
    "            next_token_indices.unsqueeze(1) * unfinished_sequences + tokenizer.pad_token_id * (1 - unfinished_sequences)\n",
    "        )\n",
    "        unfinished_sequences = unfinished_sequences.mul(\n",
    "            next_token_indices.tile(\n",
    "                eos_token_id_tensor.shape[0]\n",
    "            ).ne(eos_token_id_tensor).prod(dim = 0)\n",
    "        )\n",
    "\n",
    "        logs(unfinished_sequences, debug)\n",
    "\n",
    "        if unfinished_sequences.max() == 0 :\n",
    "            break\n",
    "\n",
    "        # print(input_ids.size())\n",
    "        # print(next_token_indices.size())\n",
    "\n",
    "        input_ids = torch.cat(\n",
    "            (\n",
    "                input_ids, \n",
    "                next_token_indices\n",
    "            ), \n",
    "            dim = 1).long()\n",
    "\n",
    "        sentence_length += 1\n",
    "    \n",
    "        print(input_ids.size(1))\n",
    "        print('-'*30)\n",
    "\n",
    "    return input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.add_special_tokens({\n",
    "    'bos_token' : '[BOS]',\n",
    "    'eos_token' : '[EOS]'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_bos_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = ['my name is kong', 'this is aditya rustagi', 'i like to eat ice cream']\n",
    "test_sentence_tokens = tokenizer.batch_encode_plus(test_sentence, padding=True, add_special_tokens = False)\n",
    "# encoder_inp = preprocess_batch(test_sentence_tokens, type='input').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my name is kong [PAD] [PAD] [PAD] [PAD]',\n",
       " 'this is aditya rustagi',\n",
       " 'i like to eat ice cream [PAD] [PAD]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(test_sentence_tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence_tokens['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence_tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output, attention_scores = model.encoder_pass(encoder_inp, encoder_mask = None)\n",
    "output_ids = generate(model, enc_output, tokenizer, max_seq_len, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BOS] Į Ι ő Ι Έ ι ǹ É ɨ œ \" * ω ǫ [unused2] ª ş £ \" *',\n",
       " \"[BOS] > l λ ũ l λ Į Ι Į Ι â [unused88] [unused58] ǫ '. ņ đ ƒ Φ\",\n",
       " '[BOS] Į Ι [unused83] Μ [unused83] Ι µ\\'¥\\'¥\\'¥\\'¥\\'Ð \" * ω']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([[[0.1, 0.3, 0.6],  # Sample 1, class probabilities\n",
    "                       [0.8, 0.1, 0.1],\n",
    "                       [0.2, 0.5, 0.3]],\n",
    "                      \n",
    "                      [[0.5, 0.2, 0.3],  # Sample 2, class probabilities\n",
    "                       [0.2, 0.6, 0.2],\n",
    "                       [0.3, 0.4, 0.3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0]])\n",
      "tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 0])\n",
      "tensor([0.0000, 2.0416, 0.0000, 0.0000, 0.0000, 2.2514, 2.5425, 2.0280, 2.6332,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2, 5, 10))\n",
    "mask = torch.randint(0, 2, (2, 5))\n",
    "b = torch.randint(0, 10, (10, 1))\n",
    "print(mask)\n",
    "print(mask.reshape(-1))\n",
    "print(criterion(a.reshape(-1, a.size(2)), b.squeeze()) * mask.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
